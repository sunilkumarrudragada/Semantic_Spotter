{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNk7ISLbSTYhWOOpreyPvxd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunilkumarrudragada/Semantic_Spotter/blob/master/Semantic_Spotter_Sunil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Problem Statement\n",
        "\n",
        "Insurance policy documents are often long, complex, and filled with technical jargon that makes it challenging for customers and agents to find specific information such as claim limits, exclusions, coverage details, and waiting periods. Traditional keyword-based searches are insufficient, as they fail to capture the contextual meaning of user queries.\n",
        "\n",
        "To address this problem, **IntelliPolicy** aims to build a **Retrieval-Augmented Generation (RAG)** system that can accurately answer natural language questions from multiple insurance policy documents. The system retrieves the most relevant sections from the documents and generates concise, context-aware responses using a Large Language Model (LLM).\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Objective\n",
        "\n",
        "The main objective of this project is to:\n",
        "- Enable users to query large insurance documents conversationally.  \n",
        "- Retrieve and summarize relevant policy details automatically.  \n",
        "- Provide accurate, context-based answers in plain language.\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Project Goals\n",
        "\n",
        "- To build an intelligent question-answering system for insurance policy documents.  \n",
        "- To enable users to extract specific information such as claim limits, exclusions, and waiting periods using natural language.  \n",
        "- To demonstrate the practical application of Retrieval-Augmented Generation (RAG) using LangChain.  \n",
        "- To showcase the integration of embeddings, vector stores, and LLMs in a real-world use case.  \n",
        "\n",
        "---\n",
        "\n",
        "## üìÇ Data Sources\n",
        "\n",
        "The project utilizes **sample available insurance policy PDFs** stored in **Google Drive**.  \n",
        "These documents include general insurance policies (e.g., health, life, or term insurance) containing coverage details, exclusions, and claim procedures.  \n",
        "\n",
        "The documents are processed using LangChain‚Äôs `PyPDFLoader` to extract textual content, which is later split into smaller chunks for embedding and retrieval.\n",
        "\n",
        "**Data Processing Workflow:**\n",
        "1. Upload the policy PDF(s) to Google Drive.  \n",
        "2. Load and parse using `PyPDFLoader`.  \n",
        "3. Split the text into semantically meaningful chunks using `RecursiveCharacterTextSplitter`.  \n",
        "4. Generate embeddings using `OpenAIEmbeddings` (model: `text-embedding-3-small`).  \n",
        "5. Store the embeddings in a vector database (Chroma) for fast and accurate retrieval.\n",
        "\n",
        "---\n",
        "\n",
        "### ü§ñ Why LangChain?\n",
        "\n",
        "**LangChain** is chosen as the core framework because it provides modular tools to seamlessly integrate document retrieval and generative AI. Specifically, LangChain supports:\n",
        "- **Document Loaders** to extract text from PDFs.  \n",
        "- **Text Splitters** to process long documents efficiently.  \n",
        "- **Embeddings and Vector Stores** (like FAISS or Chroma) for semantic search.  \n",
        "- **Retrieval and Generation Chains** for building the end-to-end RAG pipeline.  \n",
        "\n",
        "By combining these components, LangChain allows us to design a scalable, modular, and efficient generative question-answering system tailored for the insurance domain.\n"
      ],
      "metadata": {
        "id": "kB2o63lGfbK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèóÔ∏è Overall System Design\n",
        "\n",
        "The **IntelliPolicy** system is designed as an end-to-end **Retrieval-Augmented Generation (RAG)** pipeline that retrieves relevant information from insurance policy documents and generates precise, context-based answers using a Large Language Model (LLM).\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ System Workflow\n",
        "\n",
        "The overall workflow consists of the following major stages:\n",
        "\n",
        "1. **Document Loading**  \n",
        "   - Load insurance policy PDFs using LangChain‚Äôs `PyPDFLoader`.  \n",
        "   - Each document is parsed into structured text data.\n",
        "\n",
        "2. **Text Splitting**  \n",
        "   - The extracted text is divided into smaller, overlapping chunks using `RecursiveCharacterTextSplitter`.  \n",
        "   - This ensures optimal context preservation and embedding quality.\n",
        "\n",
        "3. **Embedding Generation**  \n",
        "   - Each text chunk is transformed into a high-dimensional vector representation using `OpenAIEmbeddings`.  \n",
        "   - These embeddings help capture semantic meaning for efficient retrieval.\n",
        "\n",
        "4. **Vector Store Creation**  \n",
        "   - All embeddings are stored in a vector database (like **ChromaDB**) for fast and accurate similarity search.\n",
        "\n",
        "5. **Retriever Setup**  \n",
        "   - The retriever fetches the top relevant chunks for a given query based on vector similarity.\n",
        "\n",
        "6. **LLM Integration (RAG Pipeline)**  \n",
        "   - The retrieved context is passed to the LLM (`ChatOpenAI`) to generate a concise and context-aware answer.  \n",
        "   - LangChain‚Äôs `RetrievalQA` chain is used to connect the retriever with the LLM.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ System Architecture Diagram\n",
        "\n",
        "```text\n",
        "+---------------------------+\n",
        "|   Insurance Policy PDFs   |\n",
        "+-------------+-------------+\n",
        "              |\n",
        "              v\n",
        "+---------------------------+\n",
        "|   Document Loader         |\n",
        "|  (LangChain PyPDFLoader)  |\n",
        "+-------------+-------------+\n",
        "              |\n",
        "              v\n",
        "+---------------------------+\n",
        "|   Text Splitter           |\n",
        "| (RecursiveCharacterSplitter) |\n",
        "+-------------+-------------+\n",
        "              |\n",
        "              v\n",
        "+---------------------------+\n",
        "|   Embedding Generator     |\n",
        "| (OpenAI)    |\n",
        "+-------------+-------------+\n",
        "              |\n",
        "              v\n",
        "+---------------------------+\n",
        "|   Vector Store            |\n",
        "|   (Chroma)        |\n",
        "+-------------+-------------+\n",
        "              |\n",
        "              v\n",
        "+---------------------------+\n",
        "|   Retriever + LLM         |\n",
        "| (LangChain RetrievalQA)   |\n",
        "+-------------+-------------+\n",
        "              |\n",
        "              v\n",
        "+---------------------------+\n",
        "|   User Query + Response   |\n",
        "|                           |\n",
        "+---------------------------+\n"
      ],
      "metadata": {
        "id": "J2Hx7jlsgccN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![System Design Flowchart](https://drive.google.com/uc?export=view&id=1ewWZ54BwfVSAdZfmc1yqmveUvYT1vhv7)\n"
      ],
      "metadata": {
        "id": "nKEqHwJJPU1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß© Design Choices\n",
        "\n",
        "| **Component** | **Choice** | **Reason** |\n",
        "|----------------|-------------|-------------|\n",
        "| **Framework** | LangChain | Provides modular, scalable RAG pipelines with retrievers and chains. |\n",
        "| **Vector Store** | ChromaDB | Lightweight, open-source, and easy to persist locally. |\n",
        "| **LLM Model** | GPT-3.5 Turbo | Reliable, cost-effective, and accurate for contextual question answering. |\n",
        "| **Embedding Model** | text-embedding-3-small | Efficient embedding generation for semantic similarity. |\n",
        "| **Chunking Strategy** | RecursiveCharacterTextSplitter | Maintains sentence continuity with overlapping chunks. |\n",
        "| **Memory** | Excluded | Each query is independent; memory is unnecessary for single-turn Q&A. |\n"
      ],
      "metadata": {
        "id": "C5jGSbAgKfCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚öôÔ∏è Implementation Highlights\n",
        "\n",
        "| **Aspect** | **Description** |\n",
        "|-------------|-----------------|\n",
        "| **Code Modularity** | Each component (loading, splitting, embedding, retrieval, and generation) is implemented independently for better maintainability and debugging. |\n",
        "| **Flexibility** | The system supports multiple policy documents and can be easily extended to include metadata-based filters or additional vector stores. |\n",
        "| **Transparency** | All intermediate outputs (e.g., embeddings, retrieval results) can be inspected for performance tuning and optimization. |\n",
        "| **Reproducibility** | The entire pipeline runs in Google Colab, ensuring consistent results and easy re-execution for evaluators. |\n",
        "| **Output Formatting** | The `pretty_print_rag_result()` function neatly formats the results, making them screenshot-ready for documentation and reports. |\n"
      ],
      "metadata": {
        "id": "jnIK_txjK14H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üí° Challenges Faced\n",
        "\n",
        "| **Challenge** | **Description** |\n",
        "|----------------|-----------------|\n",
        "| **PDF Text Extraction** | Extracting clean, structured text from complex insurance PDFs containing tables, footnotes, and irregular formatting was challenging. |\n",
        "| **Chunk Size Optimization** | Balancing the chunk size and overlap to retain context while staying within token limits required multiple iterations. |\n",
        "| **Embedding Performance** | Generating embeddings for large documents using OpenAI‚Äôs API introduced latency and cost considerations. |\n",
        "| **Retrieval Accuracy** | Ensuring that the retriever returns contextually relevant and precise chunks for reliable LLM responses was crucial. |\n",
        "| **Model Latency & Rate Limits** | Managing API rate limits and occasional delays when processing multiple queries in Colab during testing. |\n"
      ],
      "metadata": {
        "id": "sJjweGwKK3CB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìò How to Run the Project\n",
        "\n",
        "1. Open `Semantic_Spotter_Sunil.ipynb` in **Google Colab**.  \n",
        "2. Mount Google Drive and update the path to your insurance PDF file.  \n",
        "3. Run all code cells sequentially:\n",
        "   - Install dependencies  \n",
        "   - Load and split PDF  \n",
        "   - Create embeddings and vector store  \n",
        "   - Build the RAG pipeline  \n",
        "   - Run sample queries  \n",
        "4. Use the `pretty_print_rag_result()` function to view formatted answers.  \n",
        "5. Review the sample outputs for screenshots in your project report.\n"
      ],
      "metadata": {
        "id": "G9Xi3iCXOkjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing required libraries\n",
        "!pip install langchain langchain_community langchain-openai chromadb tiktoken pdfplumber pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGrWar8Yhzdt",
        "outputId": "b2294648-8695-411e-8be6-b7c9be7d3788"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.3.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (0.11.7)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.1.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.38)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (20250506)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (5.0.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.28.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.71.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.59b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.3.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5mj1S3AiiIh",
        "outputId": "753a18a2-5bb6-4025-8c2f-be70d50acc14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path of the PDF\n",
        "pdf_path = '/content/drive/MyDrive/GenAi_Prac/HelpMate/Project_deps/Principal-Sample-Life-Insurance-Policy.pdf'"
      ],
      "metadata": {
        "id": "JtvEkZo_itMz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "4f5fvMA7h6d4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Imports**"
      ],
      "metadata": {
        "id": "7NiF-Baqj6G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Imports\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "UKNiiQm9i4Zg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Document Loading**"
      ],
      "metadata": {
        "id": "uKPMqqEMjQuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(pdf_path)\n",
        "documents = loader.load()\n",
        "print(len(documents), \"pages loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFcm0n_WjXWj",
        "outputId": "e396f486-1fe7-41aa-e5a3-299b80e4c281"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64 pages loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Split Text into Chunks**"
      ],
      "metadata": {
        "id": "3hnMAJ82kC-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = splitter.split_documents(documents)\n",
        "print(len(chunks), \"chunks created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM3ZjUfGkCCu",
        "outputId": "94610250-cef5-4cf3-f22c-588fdef6ceaa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150 chunks created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Create Embeddings and Vector Store**"
      ],
      "metadata": {
        "id": "kggSesYrktOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    openai_api_key=OPENAI_API_KEY\n",
        ")\n",
        "\n",
        "db = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=\"./vector_store\"\n",
        ")\n",
        "db.persist()\n",
        "\n",
        "print(\"‚úÖ Vector store created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yhjCV29koz8",
        "outputId": "2e29d266-fb86-4489-e571-f76c242883bb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Vector store created successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-164773923.py:11: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  db.persist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. RAG (Retrieval + QA) Pipeline**"
      ],
      "metadata": {
        "id": "s0dqZUqUsLC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_model = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0.3,\n",
        "    openai_api_key=OPENAI_API_KEY\n",
        ")\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=qa_model,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "Q38Ce94ksUOe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.Questions**"
      ],
      "metadata": {
        "id": "xC-Sofb0tJFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pretty_print_rag_result(result, query, width=100):\n",
        "    \"\"\"\n",
        "    Nicely formats and prints the RAG response (Question, Answer, and Sources)\n",
        "    so it fits in a single Colab page for screenshots.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 120)\n",
        "    print(\"üß† INTELLIPOLICY: INSURANCE POLICY Q&A SYSTEM\")\n",
        "    print(\"=\" * 120)\n",
        "    print(f\"\\nüîπ Question:\\n{textwrap.fill(query, width=width)}\")\n",
        "\n",
        "    print(\"\\nüí¨ Assistant Answer:\\n\")\n",
        "    print(textwrap.fill(result['result'], width=width))\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 120 + \"\\n‚úÖ Response Generated Successfully!\\n\" + \"=\" * 120)\n"
      ],
      "metadata": {
        "id": "_MAzmqzm6lui"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the eligibility requirements for employees under this group insurance policy?\"\n",
        "result = rag_pipeline({\"query\": query})\n",
        "pretty_print_rag_result(result, query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH8C5-jstG7f",
        "outputId": "3abf2174-95ab-4cbb-ae99-90192b36bce4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================================================================================================\n",
            "üß† INTELLIPOLICY: INSURANCE POLICY Q&A SYSTEM\n",
            "========================================================================================================================\n",
            "\n",
            "üîπ Question:\n",
            "What are the eligibility requirements for employees under this group insurance policy?\n",
            "\n",
            "üí¨ Assistant Answer:\n",
            "\n",
            "Employees must enroll in the insurance policy to be eligible for coverage. At least 75% of all\n",
            "eligible employees must enroll to maintain eligibility under this group insurance policy.\n",
            "\n",
            "========================================================================================================================\n",
            "‚úÖ Response Generated Successfully!\n",
            "========================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"When does coverage terminate for members?\"\n",
        "result = rag_pipeline({\"query\": query})\n",
        "pretty_print_rag_result(result, query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZTNA6UftrGl",
        "outputId": "c3fcab73-d350-4041-d6a7-8c9f714c5597"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================================================================================================\n",
            "üß† INTELLIPOLICY: INSURANCE POLICY Q&A SYSTEM\n",
            "========================================================================================================================\n",
            "\n",
            "üîπ Question:\n",
            "When does coverage terminate for members?\n",
            "\n",
            "üí¨ Assistant Answer:\n",
            "\n",
            "Coverage for members terminates on the earliest of the following conditions:  a. the date this Group\n",
            "Policy is terminated;  b. the date the last premium is paid for the Member's insurance;  c. any date\n",
            "desired, if requested by the Member before that date;  d. the date the Member ceases to be a Member\n",
            "as defined in PART I;  e. the date the Member ceases to be in a class for which Member Life\n",
            "Insurance is provided;  f. the date the Member retires;  g. the date the Member ceases Active Work.\n",
            "\n",
            "========================================================================================================================\n",
            "‚úÖ Response Generated Successfully!\n",
            "========================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What does the policy state about suicide or self-inflicted injury?\"\n",
        "result = rag_pipeline({\"query\": query})\n",
        "pretty_print_rag_result(result, query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hZCphLT7N-S",
        "outputId": "826f43ac-a5e0-48cc-d5be-9fb3987ebe22"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================================================================================================\n",
            "üß† INTELLIPOLICY: INSURANCE POLICY Q&A SYSTEM\n",
            "========================================================================================================================\n",
            "\n",
            "üîπ Question:\n",
            "What does the policy state about suicide or self-inflicted injury?\n",
            "\n",
            "üí¨ Assistant Answer:\n",
            "\n",
            "The policy states that no benefits will be paid for any disability that results from willful self-\n",
            "injury or self-destruction, while sane or insane.\n",
            "\n",
            "========================================================================================================================\n",
            "‚úÖ Response Generated Successfully!\n",
            "========================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßæ Conclusion\n",
        "\n",
        "The IntelliPolicy RAG system successfully retrieves and summarizes key information from insurance policy documents using LangChain.  \n",
        "It enables users to query complex policy terms in natural language and receive accurate, context-based answers.  \n",
        "\n",
        "### Key Learnings\n",
        "- Gained hands-on experience with RAG architecture.\n",
        "- Implemented embeddings, vector stores, and retrievers using LangChain.\n",
        "- Built an interpretable and modular pipeline for document-based Q&A.\n",
        "\n",
        "### Future Enhancements\n",
        "\n",
        "- Integrate multiple policy documents with metadata-based retrieval (e.g., by insurer or policy type).\n",
        "\n",
        "- Add a Streamlit or Gradio-based web interface for end users.\n",
        "\n",
        "- Implement hybrid retrieval (semantic + keyword search) for better accuracy.\n",
        "\n",
        "- Include summarization and confidence scoring in the response.\n",
        "\n",
        "- Extend the system into a conversational assistant using LangChain‚Äôs memory for multi-turn Q&A.\n",
        "\n",
        "- Explore using local open-source LLMs (like Llama 3 or Mistral) for cost optimization.\n"
      ],
      "metadata": {
        "id": "WKiKZLmgAD9R"
      }
    }
  ]
}